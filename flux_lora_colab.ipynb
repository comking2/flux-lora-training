{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLUX LoRA Training in Google Colab\n",
    "\n",
    "이 노트북은 Google Colab에서 FLUX LoRA 훈련을 위한 환경설정 및 실행 가이드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 정보 확인\n",
    "!nvidia-smi\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 필요한 패키지 설치 (CUDA 호환성 확보)\n# PyTorch와 torchvision CUDA 버전 통일\n\n# 기존 설치된 패키지 제거 (충돌 방지)\n!pip uninstall torch torchvision torchaudio -y\n\n# 호환되는 PyTorch 버전 설치 (CUDA 11.8)\n!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n\n# 다른 필수 패키지들\n!pip install diffusers transformers peft accelerate datasets\n!pip install Pillow pandas numpy tqdm wandb safetensors\n!pip install sentencepiece protobuf python-dotenv\n\n# 설치 확인\nimport torch\nprint(f\"✅ PyTorch version: {torch.__version__}\")\nprint(f\"✅ CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"✅ CUDA version: {torch.version.cuda}\")\n    print(f\"✅ GPU: {torch.cuda.get_device_name()}\")\n    print(f\"✅ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# 환경변수 및 GitHub 토큰 설정\nimport os\nfrom google.colab import userdata\n\n# 방법 1: Colab Secrets 사용 (권장)\n# 🔑 키 아이콘 클릭 → Add new secret:\n# HUGGINGFACE_TOKEN: hf_your_token_here\n# GITHUB_TOKEN: ghp_your_token_here (Private 저장소용)\n\ntry:\n    HF_TOKEN = userdata.get('HUGGINGFACE_TOKEN')\n    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n    \n    os.environ['HUGGINGFACE_TOKEN'] = HF_TOKEN\n    os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n    \n    print(\"✅ Tokens loaded from Colab secrets\")\nexcept:\n    # 방법 2: 직접 입력 (임시용)\n    HF_TOKEN = \"hf_your_token_here\"\n    GITHUB_TOKEN = \"ghp_your_token_here\"\n    \n    os.environ['HUGGINGFACE_TOKEN'] = HF_TOKEN\n    os.environ['GITHUB_TOKEN'] = GITHUB_TOKEN\n    \n    print(\"⚠️ Tokens set manually\")\n\n# 기타 환경변수 설정\nos.environ['FLUX_MODEL_NAME'] = 'black-forest-labs/FLUX.1-schnell'\nos.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\nprint(\"✅ Environment variables configured\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Private GitHub 저장소 클로닝\nimport os\n\n# GitHub 토큰 확인\ngithub_token = os.environ.get('GITHUB_TOKEN')\n\nif github_token and github_token != \"ghp_your_token_here\":\n    # 토큰을 사용한 Private 저장소 클로닝\n    !git clone https://{github_token}@github.com/comking2/flux-lora-training.git\n    print(\"✅ Private repository cloned successfully\")\nelse:\n    # 토큰이 없으면 Public 저장소 시도 또는 수동 업로드 안내\n    try:\n        !git clone https://github.com/comking2/flux-lora-training.git\n        print(\"✅ Public repository cloned\")\n    except:\n        print(\"❌ Repository access failed\")\n        print(\"💡 해결방법:\")\n        print(\"1. GitHub Token을 Colab Secrets에 추가\")\n        print(\"2. 또는 저장소를 Public으로 변경\")\n        print(\"3. 또는 파일을 직접 업로드\")\n\n# 클로닝된 디렉토리로 이동\ntry:\n    %cd flux-lora-training\n    print(\"📁 Moved to project directory\")\n    \n    # 파일 목록 확인\n    !ls -la\nexcept:\n    print(\"⚠️ Directory not found - please check cloning status\")"
  },
  {
   "cell_type": "code",
   "source": "# 대안: 개별 파일 다운로드 (클로닝 실패 시)\n# GitHub Token이 없거나 Private 저장소 접근이 안 될 때 사용\n\nprint(\"🔄 Alternative: Downloading individual files...\")\n\n# 주요 파일들을 개별적으로 다운로드\nfiles_to_download = [\n    'train_lora.py',\n    'dataset_processor.py', \n    'inference.py',\n    'config.json',\n    'requirements.txt',\n    '.env.example'\n]\n\nimport requests\nimport os\n\ndef download_file(filename, token=None):\n    if token:\n        url = f\"https://api.github.com/repos/comking2/flux-lora-training/contents/{filename}\"\n        headers = {'Authorization': f'token {token}'}\n        response = requests.get(url, headers=headers)\n        if response.status_code == 200:\n            import base64\n            content = base64.b64decode(response.json()['content']).decode('utf-8')\n            with open(filename, 'w') as f:\n                f.write(content)\n            return True\n    return False\n\n# GitHub API를 통한 다운로드 시도\ngithub_token = os.environ.get('GITHUB_TOKEN')\ndownloaded = []\n\nfor filename in files_to_download:\n    if download_file(filename, github_token):\n        downloaded.append(filename)\n        print(f\"✅ Downloaded: {filename}\")\n    else:\n        print(f\"❌ Failed: {filename}\")\n\nif downloaded:\n    print(f\"\\\\n✅ Successfully downloaded {len(downloaded)} files\")\n    !ls -la\nelse:\n    print(\"\\\\n💡 Please upload files manually or provide GitHub token\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 업로드 또는 다운로드\n",
    "# 방법 1: Google Drive 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 방법 2: 직접 업로드\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 메모리 최적화 설정\n",
    "import torch\n",
    "\n",
    "# GPU 메모리 확인\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "    \n",
    "    # 메모리 캐시 정리\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLUX LoRA 훈련 실행\n",
    "# T4 (16GB) 환경 최적화\n",
    "\n",
    "!python train_lora.py \\\n",
    "    --data_dir \"/content/drive/MyDrive/training_data\" \\\n",
    "    --output_dir \"./flux_lora_output\" \\\n",
    "    --epochs 10 \\\n",
    "    --batch_size 1 \\\n",
    "    --lora_rank 8 \\\n",
    "    --learning_rate 5e-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}